We're building an extensible composite AI voice-agent browser SDK. It will be called `composite-voice` and likely published as `@lukeocodes/composite-voice`

It should be EXTREMELY lightweight. EXTENSIBLE AS FUCK. STRICT TYPING. Optional support for additional text input and output features per provider.

It NEEDS architecture for:

- REST AND WebSocket provider types
- STT / LLM / TTS providers
- All-in-one providers
- Uses provider SDKs where possible

Comes with:

- STT native provider (browser-native transcription)
- TTS native provider (browser-native voice synthesis)
- Built-in OpenAI and Anthropic LLM providers
- Built-in Deepgram and OpenAI STT providers
- Built-in Deepgram and Elevenlabs TTS providers
- Built-in Deepgram All-in-one provider

It will use:

- TypeScript
- Jest
- PNPM

It should normalise the Agentic experience to the client using an event emitter / pubsub:

- Restful providers will just be larger single events
- Streaming providers will support chunks

Transcription:

- Support microphone streaming to streaming providers.
- Support microphone recording and submission to rest providers.

TTS:

- Support playback of single audio response events with fixed mimetypes
- Support playback of octet-stream as soon as we have "enough" audio
- Support stitching of websocket audio chunks into a playback stream, requires the provider to also send back samplerate/encoding for the browser media playback

REST Transcription: Send entire audio in one go. Receive a text response that is sent to the LLM.
WSS Transcription: Send microphone events to the provider. Receive multiple text responses. Each provider will need to configure what event is meant to be sent to the LLM. Providers can send preflight events (context before all the text is transcribed, usually end-of-turn aware), or finalised events (the end of the thought/turn)

REST TTS: Send text in one go. Receive entire audio in one go, or as an octet-stream.
WSS TTS: Send text in multiple messages. Responsible for a finalize when to process any remaining text. Can receive chunks of audio any time after text is sent. Receive chunks of audio and metadata.

LLMs: Always receive text in one go. Can stream text back, but REST TTS will always wait for it to finish before sending. WSS TTS that supports streamed text can start to process TTS before the text finishes.
