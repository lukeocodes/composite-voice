# Cursor: Setup Deepgram TTS Provider

## Date

2025-01-19

## Objective

Set up a Deepgram TTS (Text-to-Speech) provider in the providers architecture, supporting live TTS only via WebSocket.

## Context

Following the same architectural pattern as the DeepgramSTT provider, create a complete TTS provider implementation that:

- Uses the official Deepgram SDK as a peer dependency
- Operates exclusively in WebSocket mode for real-time streaming synthesis
- Supports all Deepgram TTS voice models and configuration options
- Includes comprehensive unit tests and documentation

## Changes Made

### New Files Created

1. **Provider Implementation**
   - `src/providers/tts/deepgram/DeepgramTTS.ts` - Main provider class
   - `src/providers/tts/deepgram/index.ts` - Export file

2. **Unit Tests**
   - `tests/unit/providers/tts/DeepgramTTS.test.ts` - Comprehensive test suite (25 tests)

3. **Documentation**
   - `docs/Deepgram TTS Provider.md` - Complete provider documentation

### Files Modified

1. **Provider Exports**
   - `src/providers/tts/index.ts` - Updated comments to include Deepgram TTS

2. **Documentation**
   - `docs/README.md` - Added Deepgram TTS Provider section

## Implementation Details

### Provider Architecture

The DeepgramTTS provider follows the established architecture pattern:

```typescript
export class DeepgramTTS extends BaseTTSProvider {
  // WebSocket-only provider
  type: 'websocket';

  // Lifecycle methods
  protected async onInitialize(): Promise<void>;
  protected async onDispose(): Promise<void>;

  // WebSocket operations
  override async connect(): Promise<void>;
  override sendText(text: string): void;
  override async finalize(): Promise<void>;
  override async disconnect(): Promise<void>;

  // Connection state
  isWebSocketConnected(): boolean;
}
```

### Configuration Options

```typescript
interface DeepgramTTSConfig {
  apiKey: string; // Required
  voice?: string; // Default: 'aura-asteria-en'
  sampleRate?: number; // Default: 16000
  outputFormat?: string; // Default: 'linear16'
  timeout?: number; // Default: 10000
  options?: {
    model?: string;
    encoding?: string;
    sampleRate?: number;
    container?: string;
    bitRate?: number;
  };
}
```

### Supported Voice Models

The provider supports 12+ Deepgram voice models:

- Female voices: aura-asteria-en, aura-luna-en, aura-stella-en, aura-athena-en, aura-hera-en
- Male voices: aura-orion-en, aura-arcas-en, aura-perseus-en, aura-angus-en, aura-orpheus-en, aura-helios-en, aura-zeus-en

### Event Handling

The provider handles the following WebSocket events:

- `Open` - Connection established
- `Audio` - Audio data received
- `Metadata` - Metadata received
- `Flushed` - All audio sent
- `Error` - Error occurred
- `Warning` - Warning received
- `Close` - Connection closed

### Audio Processing

Audio data handling:

- Accepts both ArrayBuffer and Buffer types from SDK
- Converts Buffer to ArrayBuffer for consistency
- Emits AudioChunk with metadata (sample rate, encoding, channels, bit depth)
- Supports streaming synthesis with progressive text chunks

## Technical Challenges

### Type Safety with Peer Dependencies

**Challenge**: The Deepgram SDK's LiveTTSClient type may not be exported in all versions.

**Solution**: Used `any` type with a comment explaining the limitation:

```typescript
// Note: Using 'any' for LiveTTSClient as the type may not be exported in all SDK versions
type LiveTTSClient = any;
```

### ArrayBuffer vs SharedArrayBuffer

**Challenge**: Buffer.slice() can return either ArrayBuffer or SharedArrayBuffer, but AudioChunk.data must be ArrayBuffer.

**Solution**: Explicitly convert to ArrayBuffer by creating a new buffer and copying data:

```typescript
arrayBuffer = new ArrayBuffer(buffer.byteLength);
const view = new Uint8Array(arrayBuffer);
view.set(new Uint8Array(buffer.buffer, buffer.byteOffset, buffer.byteLength));
```

## Test Coverage

Created comprehensive test suite with 25 tests covering:

### Initialization Tests (4 tests)

- Default configuration
- Custom configuration
- SDK not installed error
- Disposal

### WebSocket Mode Tests (17 tests)

- Connection success/failure
- Configuration options
- Timeout and error handling
- Text sending
- Audio data processing (ArrayBuffer and Buffer)
- Metadata processing
- Flush events
- Finalization
- Disconnection
- Multiple text chunks

### Configuration Tests (4 tests)

- Configuration retrieval
- All TTS options
- Different voice models (12 voices tested)

All tests pass: **250/250 tests passing** (includes existing tests)

## Documentation

Created comprehensive documentation including:

### Core Sections

- Overview and features
- Installation instructions
- Basic and advanced usage examples
- Configuration reference
- Voice model table
- WebSocket lifecycle explanation

### Advanced Topics

- Audio chunk handling
- Streaming long text
- Error handling patterns
- Performance considerations
- Latency and quality optimization
- Integration with CompositeVoice

### Reference Material

- Complete API reference
- Troubleshooting guide
- Best practices
- External resource links

## Integration Example

```typescript
import { DeepgramTTS } from '@lukeocodes/composite-voice/providers/tts/deepgram';

const tts = new DeepgramTTS({
  apiKey: 'your-api-key',
  voice: 'aura-asteria-en',
  sampleRate: 24000,
});

await tts.initialize();
await tts.connect();

tts.onAudio((chunk) => {
  audioPlayer.play(chunk);
});

tts.sendText('Hello, this is streaming text-to-speech!');
await tts.finalize();
await tts.disconnect();
```

## Verification

All verification steps passed:

1. ✅ TypeScript compilation (`pnpm run type-check`)
2. ✅ All unit tests pass (250/250 tests)
3. ✅ Build successful (`pnpm run build`)
4. ✅ No linter errors
5. ✅ Documentation complete and formatted

## Files Changed Summary

### New Provider Files

- `src/providers/tts/deepgram/DeepgramTTS.ts` (362 lines)
- `src/providers/tts/deepgram/index.ts` (5 lines)

### New Test Files

- `tests/unit/providers/tts/DeepgramTTS.test.ts` (537 lines)

### New Documentation

- `docs/Deepgram TTS Provider.md` (438 lines)

### Modified Files

- `src/providers/tts/index.ts` (comment updates)
- `docs/README.md` (added Deepgram TTS section)

## Next Steps

Potential future enhancements:

1. Add REST API support for non-streaming synthesis
2. Add support for SSML (Speech Synthesis Markup Language)
3. Add audio format conversion utilities
4. Add voice customization options (pitch, speed, etc.)
5. Add integration examples with audio players
6. Add browser-specific optimizations

## Related Work

This provider complements:

- DeepgramSTT provider (for speech-to-text)
- OpenAI LLM provider (for language understanding)
- Complete STT → LLM → TTS pipeline

Together, these providers enable a complete voice agent implementation using Deepgram and OpenAI services.
